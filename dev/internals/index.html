<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Internals · LinearAlgebraMPI.jl</title><meta name="title" content="Internals · LinearAlgebraMPI.jl"/><meta property="og:title" content="Internals · LinearAlgebraMPI.jl"/><meta property="twitter:title" content="Internals · LinearAlgebraMPI.jl"/><meta name="description" content="Documentation for LinearAlgebraMPI.jl."/><meta property="og:description" content="Documentation for LinearAlgebraMPI.jl."/><meta property="twitter:description" content="Documentation for LinearAlgebraMPI.jl."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">LinearAlgebraMPI.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../getting-started/">Getting Started</a></li><li><a class="tocitem" href="../examples/">Examples</a></li><li><a class="tocitem" href="../api/">API Reference</a></li><li class="is-active"><a class="tocitem" href>Internals</a><ul class="internal"><li><a class="tocitem" href="#Data-Structures"><span>Data Structures</span></a></li><li><a class="tocitem" href="#Matrix-Multiplication-Algorithm"><span>Matrix Multiplication Algorithm</span></a></li><li><a class="tocitem" href="#Transpose-Algorithm"><span>Transpose Algorithm</span></a></li><li><a class="tocitem" href="#Addition/Subtraction"><span>Addition/Subtraction</span></a></li><li><a class="tocitem" href="#Lazy-Transpose"><span>Lazy Transpose</span></a></li><li><a class="tocitem" href="#Communication-Patterns"><span>Communication Patterns</span></a></li><li><a class="tocitem" href="#Memory-Management"><span>Memory Management</span></a></li><li><a class="tocitem" href="#Testing-Considerations"><span>Testing Considerations</span></a></li><li><a class="tocitem" href="#Performance-Considerations"><span>Performance Considerations</span></a></li><li><a class="tocitem" href="#Extending-the-Library"><span>Extending the Library</span></a></li><li><a class="tocitem" href="#Debugging-Tips"><span>Debugging Tips</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Internals</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Internals</a></li></ul></nav><div class="docs-right"><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Internals"><a class="docs-heading-anchor" href="#Internals">Internals</a><a id="Internals-1"></a><a class="docs-heading-anchor-permalink" href="#Internals" title="Permalink"></a></h1><p>This page describes the internal architecture and implementation details of LinearAlgebraMPI.jl. Understanding these details can help with debugging, performance optimization, and extending the library.</p><h2 id="Data-Structures"><a class="docs-heading-anchor" href="#Data-Structures">Data Structures</a><a id="Data-Structures-1"></a><a class="docs-heading-anchor-permalink" href="#Data-Structures" title="Permalink"></a></h2><h3 id="SparseMatrixMPI-Storage"><a class="docs-heading-anchor" href="#SparseMatrixMPI-Storage">SparseMatrixMPI Storage</a><a id="SparseMatrixMPI-Storage-1"></a><a class="docs-heading-anchor-permalink" href="#SparseMatrixMPI-Storage" title="Permalink"></a></h3><p><code>SparseMatrixMPI{T}</code> stores a distributed sparse matrix with the following key design decisions:</p><ol><li><strong>Row partitioning</strong>: Rows are distributed roughly equally across MPI ranks</li><li><strong>Transposed storage</strong>: Local rows are stored as the <strong>transpose</strong> (<code>AT::SparseMatrixCSC</code>)</li><li><strong>Global indices</strong>: Column indices in <code>AT.rowval</code> are global (not local) indices</li></ol><h4 id="Why-Store-the-Transpose?"><a class="docs-heading-anchor" href="#Why-Store-the-Transpose?">Why Store the Transpose?</a><a id="Why-Store-the-Transpose?-1"></a><a class="docs-heading-anchor-permalink" href="#Why-Store-the-Transpose?" title="Permalink"></a></h4><p>Storing the transpose (columns of <code>AT</code> = rows of <code>A</code>) has several advantages:</p><ul><li><strong>Efficient row access</strong>: CSC format provides O(1) access to column slices. Since we store <code>AT</code>, we get O(1) access to rows of <code>A</code>.</li><li><strong>Natural for multiplication</strong>: In <code>A * B</code>, we need to iterate over rows of <code>A</code> and columns of <code>B</code>. With <code>AT</code> stored, iterating over rows of <code>A</code> is efficient.</li><li><strong>Simplified communication</strong>: When gathering rows from <code>B</code> for multiplication, we can directly send column slices of <code>B.AT</code>.</li></ul><h4 id="Field-Descriptions"><a class="docs-heading-anchor" href="#Field-Descriptions">Field Descriptions</a><a id="Field-Descriptions-1"></a><a class="docs-heading-anchor-permalink" href="#Field-Descriptions" title="Permalink"></a></h4><pre><code class="language-julia hljs">struct SparseMatrixMPI{T}
    structural_hash::NTuple{32,UInt8}  # Blake3 hash for plan caching
    row_partition::Vector{Int}          # [1, r1_end+1, r2_end+1, ..., nrows+1]
    col_partition::Vector{Int}          # Similar for columns (for transpose)
    col_indices::Vector{Int}            # Unique sorted column indices in local part
    AT::SparseMatrixCSC{T,Int}          # Transposed local rows
end</code></pre><p><strong>Invariants:</strong></p><ul><li><code>row_partition[1] = 1</code></li><li><code>row_partition[end] = nrows + 1</code></li><li><code>size(AT, 2) = row_partition[rank+2] - row_partition[rank+1]</code> (local row count)</li><li><code>AT.rowval</code> contains global column indices</li></ul><h3 id="Structural-Hashing"><a class="docs-heading-anchor" href="#Structural-Hashing">Structural Hashing</a><a id="Structural-Hashing-1"></a><a class="docs-heading-anchor-permalink" href="#Structural-Hashing" title="Permalink"></a></h3><p>Each <code>SparseMatrixMPI</code> has a 256-bit Blake3 hash of its structure. This hash is:</p><ol><li><strong>Computed collectively</strong>: Uses <code>Allgather</code> to ensure identical hash on all ranks</li><li><strong>Structure-only</strong>: Includes partition, indices, <code>colptr</code>, <code>rowval</code> (not values)</li><li><strong>Used for plan caching</strong>: Same structure = same communication pattern</li></ol><p>The hash computation:</p><ol><li>Each rank hashes its local data (row<em>partition, col</em>indices, AT.colptr, AT.rowval)</li><li>All local hashes are gathered via <code>MPI.Allgather</code></li><li>The gathered hashes are hashed together to produce the global hash</li></ol><h2 id="Matrix-Multiplication-Algorithm"><a class="docs-heading-anchor" href="#Matrix-Multiplication-Algorithm">Matrix Multiplication Algorithm</a><a id="Matrix-Multiplication-Algorithm-1"></a><a class="docs-heading-anchor-permalink" href="#Matrix-Multiplication-Algorithm" title="Permalink"></a></h2><h3 id="Overview"><a class="docs-heading-anchor" href="#Overview">Overview</a><a id="Overview-1"></a><a class="docs-heading-anchor-permalink" href="#Overview" title="Permalink"></a></h3><p>Computing <code>C = A * B</code> requires three phases:</p><ol><li><strong>Plan creation</strong>: Determine which rows of <code>B</code> are needed and exchange sparsity structure</li><li><strong>Value exchange</strong>: Send/receive the actual matrix values</li><li><strong>Local computation</strong>: Multiply the gathered data locally</li></ol><h3 id="Phase-1:-Plan-Creation"><a class="docs-heading-anchor" href="#Phase-1:-Plan-Creation">Phase 1: Plan Creation</a><a id="Phase-1:-Plan-Creation-1"></a><a class="docs-heading-anchor-permalink" href="#Phase-1:-Plan-Creation" title="Permalink"></a></h3><p>When creating a <code>MatrixPlan(A, B)</code>:</p><ol><li><strong>Identify needed rows</strong>: <code>A.col_indices</code> tells us which columns of <code>A</code> (= rows of <code>B</code>) we need</li><li><strong>Determine owners</strong>: For each needed row, find which rank owns it using <code>B.row_partition</code></li><li><strong>Exchange requests</strong>: Use <code>Alltoall</code> to exchange counts, then point-to-point for row lists</li><li><strong>Exchange structure</strong>: Send <code>colptr</code> and <code>rowval</code> for requested rows</li><li><strong>Build gathered structure</strong>: Construct <code>plan.AT</code> with zeros (sparsity pattern only)</li><li><strong>Setup buffers</strong>: Pre-allocate send/receive buffers and track offsets</li></ol><h3 id="Phase-2:-Value-Exchange-(execute_plan!)"><a class="docs-heading-anchor" href="#Phase-2:-Value-Exchange-(execute_plan!)">Phase 2: Value Exchange (execute_plan!)</a><a id="Phase-2:-Value-Exchange-(execute_plan!)-1"></a><a class="docs-heading-anchor-permalink" href="#Phase-2:-Value-Exchange-(execute_plan!)" title="Permalink"></a></h3><ol><li><strong>Local copy</strong>: Copy values for locally-owned rows directly into <code>plan.AT.nzval</code></li><li><strong>Pack and send</strong>: For each remote rank, pack requested values into buffer and <code>Isend</code></li><li><strong>Receive</strong>: <code>Irecv</code> values from ranks we requested data from</li><li><strong>Unpack</strong>: Copy received values into <code>plan.AT.nzval</code> at correct offsets</li></ol><h3 id="Phase-3:-Local-Computation"><a class="docs-heading-anchor" href="#Phase-3:-Local-Computation">Phase 3: Local Computation</a><a id="Phase-3:-Local-Computation-1"></a><a class="docs-heading-anchor-permalink" href="#Phase-3:-Local-Computation" title="Permalink"></a></h3><pre><code class="language-julia hljs"># C^T = B^T * A^T = plan.AT * A.AT_reindexed
result_AT = plan.AT * A_AT_reindexed</code></pre><p>The key insight is that we need to reindex <code>A.AT.rowval</code> from global indices to local indices (1:n_gathered) since <code>plan.AT</code> has only the gathered rows, not all of <code>B</code>.</p><h3 id="Plan-Caching"><a class="docs-heading-anchor" href="#Plan-Caching">Plan Caching</a><a id="Plan-Caching-1"></a><a class="docs-heading-anchor-permalink" href="#Plan-Caching" title="Permalink"></a></h3><p>Plans are cached in a global dictionary keyed by <code>(A.structural_hash, B.structural_hash, T)</code>. This means:</p><ul><li>Repeated multiplications with the same structure reuse plans</li><li>The structure can be different values (plans only depend on sparsity)</li><li>Plans must be cleared manually with <code>clear_plan_cache!()</code> when done</li></ul><h2 id="Transpose-Algorithm"><a class="docs-heading-anchor" href="#Transpose-Algorithm">Transpose Algorithm</a><a id="Transpose-Algorithm-1"></a><a class="docs-heading-anchor-permalink" href="#Transpose-Algorithm" title="Permalink"></a></h2><h3 id="TransposePlan-Creation"><a class="docs-heading-anchor" href="#TransposePlan-Creation">TransposePlan Creation</a><a id="TransposePlan-Creation-1"></a><a class="docs-heading-anchor-permalink" href="#TransposePlan-Creation" title="Permalink"></a></h3><p>The transpose of <code>A</code> (with row<em>partition <code>R</code> and col</em>partition <code>C</code>) has:</p><ul><li><code>row_partition = C</code> (columns become rows)</li><li><code>col_partition = R</code> (rows become columns)</li></ul><p>Algorithm:</p><ol><li><strong>Categorize nonzeros</strong>: For each <code>A[i,j]</code>, determine which rank owns row <code>j</code> in <code>A^T</code></li><li><strong>Exchange structure</strong>: Send <code>(row, col)</code> pairs to destination ranks</li><li><strong>Build sparse structure</strong>: Construct CSC format for the transposed matrix</li><li><strong>Setup communication</strong>: Track permutations for scattering received values</li></ol><h3 id="execute_plan!-for-Transpose"><a class="docs-heading-anchor" href="#execute_plan!-for-Transpose">execute_plan! for Transpose</a><a id="execute_plan!-for-Transpose-1"></a><a class="docs-heading-anchor-permalink" href="#execute_plan!-for-Transpose" title="Permalink"></a></h3><ol><li>Copy local values (entries that stay on the same rank)</li><li>Pack and send values to destination ranks</li><li>Receive values and scatter into result using pre-computed permutation</li></ol><h2 id="Addition/Subtraction"><a class="docs-heading-anchor" href="#Addition/Subtraction">Addition/Subtraction</a><a id="Addition/Subtraction-1"></a><a class="docs-heading-anchor-permalink" href="#Addition/Subtraction" title="Permalink"></a></h2><p>For <code>A + B</code> or <code>A - B</code>:</p><ol><li><strong>Get addition plan</strong>: Gather B&#39;s rows to match A&#39;s partition</li><li><strong>Execute plan</strong>: Redistribute B&#39;s values</li><li><strong>Local operation</strong>: Use SparseArrays&#39; built-in <code>A.AT + plan.AT</code> or <code>A.AT - plan.AT</code></li></ol><p>The result inherits A&#39;s partition.</p><h2 id="Lazy-Transpose"><a class="docs-heading-anchor" href="#Lazy-Transpose">Lazy Transpose</a><a id="Lazy-Transpose-1"></a><a class="docs-heading-anchor-permalink" href="#Lazy-Transpose" title="Permalink"></a></h2><p>Lazy transpose uses Julia&#39;s <code>LinearAlgebra.Transpose</code> wrapper:</p><pre><code class="language-julia hljs">transpose(A::SparseMatrixMPI{T}) = Transpose(A)</code></pre><p>Operations with lazy transposes are handled by specialized methods:</p><ul><li><code>transpose(A) * transpose(B)</code> returns <code>transpose(B * A)</code> (computed lazily)</li><li><code>transpose(A) * B</code> materializes <code>A^T</code> first, then multiplies</li><li><code>A * transpose(B)</code> materializes <code>B^T</code> first, then multiplies</li><li><code>a * transpose(A)</code> returns <code>transpose(a * A)</code></li></ul><h2 id="Communication-Patterns"><a class="docs-heading-anchor" href="#Communication-Patterns">Communication Patterns</a><a id="Communication-Patterns-1"></a><a class="docs-heading-anchor-permalink" href="#Communication-Patterns" title="Permalink"></a></h2><h3 id="Alltoall-Pattern"><a class="docs-heading-anchor" href="#Alltoall-Pattern">Alltoall Pattern</a><a id="Alltoall-Pattern-1"></a><a class="docs-heading-anchor-permalink" href="#Alltoall-Pattern" title="Permalink"></a></h3><p>Used for exchanging counts and sizes:</p><pre><code class="language-julia hljs">recv_counts = MPI.Alltoall(MPI.UBuffer(send_counts, 1), comm)</code></pre><h3 id="Point-to-Point-Pattern"><a class="docs-heading-anchor" href="#Point-to-Point-Pattern">Point-to-Point Pattern</a><a id="Point-to-Point-Pattern-1"></a><a class="docs-heading-anchor-permalink" href="#Point-to-Point-Pattern" title="Permalink"></a></h3><p>Used for variable-size data:</p><pre><code class="language-julia hljs"># Non-blocking send
req = MPI.Isend(msg, comm; dest=r, tag=1)

# Non-blocking receive
req = MPI.Irecv!(buf, comm; source=r, tag=1)

# Wait for completion
MPI.Waitall(reqs)</code></pre><h3 id="Collective-Reduction"><a class="docs-heading-anchor" href="#Collective-Reduction">Collective Reduction</a><a id="Collective-Reduction-1"></a><a class="docs-heading-anchor-permalink" href="#Collective-Reduction" title="Permalink"></a></h3><p>Used for norms:</p><pre><code class="language-julia hljs">global_sum = MPI.Allreduce(local_sum, MPI.SUM, comm)
global_max = MPI.Allreduce(local_max, MPI.MAX, comm)</code></pre><h2 id="Memory-Management"><a class="docs-heading-anchor" href="#Memory-Management">Memory Management</a><a id="Memory-Management-1"></a><a class="docs-heading-anchor-permalink" href="#Memory-Management" title="Permalink"></a></h2><h3 id="Pre-allocated-Buffers"><a class="docs-heading-anchor" href="#Pre-allocated-Buffers">Pre-allocated Buffers</a><a id="Pre-allocated-Buffers-1"></a><a class="docs-heading-anchor-permalink" href="#Pre-allocated-Buffers" title="Permalink"></a></h3><p>Plans pre-allocate all buffers during construction:</p><ul><li><code>send_bufs</code>: One per destination rank</li><li><code>recv_bufs</code>: One per source rank</li><li><code>plan.AT.nzval</code>: Output values array</li></ul><p>This makes <code>execute_plan!</code> allocation-free for the communication portions.</p><h3 id="Plan-Reuse"><a class="docs-heading-anchor" href="#Plan-Reuse">Plan Reuse</a><a id="Plan-Reuse-1"></a><a class="docs-heading-anchor-permalink" href="#Plan-Reuse" title="Permalink"></a></h3><p>Plans store all communication metadata:</p><ul><li>Which ranks to communicate with</li><li>Buffer sizes and offsets</li><li>Value permutations</li></ul><p>Reusing plans avoids the expensive setup phase.</p><h2 id="Testing-Considerations"><a class="docs-heading-anchor" href="#Testing-Considerations">Testing Considerations</a><a id="Testing-Considerations-1"></a><a class="docs-heading-anchor-permalink" href="#Testing-Considerations" title="Permalink"></a></h2><h3 id="Deterministic-Test-Data"><a class="docs-heading-anchor" href="#Deterministic-Test-Data">Deterministic Test Data</a><a id="Deterministic-Test-Data-1"></a><a class="docs-heading-anchor-permalink" href="#Deterministic-Test-Data" title="Permalink"></a></h3><p>Tests must use deterministic data to ensure all ranks have identical input:</p><pre><code class="language-julia hljs"># Bad: different on each rank
A = sprand(100, 100, 0.01)

# Good: deterministic
I = [1:n; 1:n-1; 2:n]
J = [1:n; 2:n; 1:n-1]
V = [2.0*ones(n); -0.5*ones(n-1); -0.5*ones(n-1)]
A = sparse(I, J, V, n, n)</code></pre><h3 id="Test-Harness"><a class="docs-heading-anchor" href="#Test-Harness">Test Harness</a><a id="Test-Harness-1"></a><a class="docs-heading-anchor-permalink" href="#Test-Harness" title="Permalink"></a></h3><p>Tests run under <code>mpiexec</code> via the test harness:</p><pre><code class="language-julia hljs">mpiexec -n 4 julia --project=. test/test_*.jl</code></pre><p>The <code>runtests.jl</code> file automates this using <code>run_mpi_test()</code>.</p><h2 id="Performance-Considerations"><a class="docs-heading-anchor" href="#Performance-Considerations">Performance Considerations</a><a id="Performance-Considerations-1"></a><a class="docs-heading-anchor-permalink" href="#Performance-Considerations" title="Permalink"></a></h2><h3 id="When-to-Clear-Cache"><a class="docs-heading-anchor" href="#When-to-Clear-Cache">When to Clear Cache</a><a id="When-to-Clear-Cache-1"></a><a class="docs-heading-anchor-permalink" href="#When-to-Clear-Cache" title="Permalink"></a></h3><p>Clear the plan cache when:</p><ul><li>You&#39;re done with a set of matrices</li><li>Memory usage is a concern</li><li>You&#39;re about to work with different matrices</li></ul><pre><code class="language-julia hljs">clear_plan_cache!()</code></pre><h3 id="Optimal-Matrix-Sizes"><a class="docs-heading-anchor" href="#Optimal-Matrix-Sizes">Optimal Matrix Sizes</a><a id="Optimal-Matrix-Sizes-1"></a><a class="docs-heading-anchor-permalink" href="#Optimal-Matrix-Sizes" title="Permalink"></a></h3><ul><li><strong>Too small</strong>: Communication overhead dominates</li><li><strong>Too large per rank</strong>: Memory limits</li><li><strong>Sweet spot</strong>: Large enough matrices with good sparsity distribution</li></ul><h3 id="Sparsity-Pattern-Impact"><a class="docs-heading-anchor" href="#Sparsity-Pattern-Impact">Sparsity Pattern Impact</a><a id="Sparsity-Pattern-Impact-1"></a><a class="docs-heading-anchor-permalink" href="#Sparsity-Pattern-Impact" title="Permalink"></a></h3><ul><li><strong>Banded matrices</strong>: Good locality, less communication</li><li><strong>Random sparse</strong>: More communication, but still efficient</li><li><strong>Block diagonal</strong>: Excellent if blocks align with partitions</li></ul><h2 id="Extending-the-Library"><a class="docs-heading-anchor" href="#Extending-the-Library">Extending the Library</a><a id="Extending-the-Library-1"></a><a class="docs-heading-anchor-permalink" href="#Extending-the-Library" title="Permalink"></a></h2><h3 id="Adding-New-Operations"><a class="docs-heading-anchor" href="#Adding-New-Operations">Adding New Operations</a><a id="Adding-New-Operations-1"></a><a class="docs-heading-anchor-permalink" href="#Adding-New-Operations" title="Permalink"></a></h3><p>To add a new operation:</p><ol><li>Determine the communication pattern</li><li>Create a plan type if needed</li><li>Implement the plan constructor</li><li>Implement <code>execute_plan!</code></li><li>Implement the high-level operation (e.g., <code>Base.:*(...)</code>)</li><li>Add caching if the operation will be repeated</li></ol><h3 id="Supporting-New-Element-Types"><a class="docs-heading-anchor" href="#Supporting-New-Element-Types">Supporting New Element Types</a><a id="Supporting-New-Element-Types-1"></a><a class="docs-heading-anchor-permalink" href="#Supporting-New-Element-Types" title="Permalink"></a></h3><p>The library is generic over element type <code>T</code>. To support a new type:</p><ol><li>Ensure it works with SparseArrays</li><li>Ensure MPI can serialize it (or provide custom serialization)</li><li>Ensure Blake3Hash can hash it</li></ol><h2 id="Debugging-Tips"><a class="docs-heading-anchor" href="#Debugging-Tips">Debugging Tips</a><a id="Debugging-Tips-1"></a><a class="docs-heading-anchor-permalink" href="#Debugging-Tips" title="Permalink"></a></h2><h3 id="Verify-Identical-Input"><a class="docs-heading-anchor" href="#Verify-Identical-Input">Verify Identical Input</a><a id="Verify-Identical-Input-1"></a><a class="docs-heading-anchor-permalink" href="#Verify-Identical-Input" title="Permalink"></a></h3><pre><code class="language-julia hljs">A_hash = compute_structural_hash(...)
# Hash should be identical on all ranks</code></pre><h3 id="Check-Partitions"><a class="docs-heading-anchor" href="#Check-Partitions">Check Partitions</a><a id="Check-Partitions-1"></a><a class="docs-heading-anchor-permalink" href="#Check-Partitions" title="Permalink"></a></h3><pre><code class="language-julia hljs">println(&quot;Rank $rank: rows $(A.row_partition[rank+1]) to $(A.row_partition[rank+2]-1)&quot;)</code></pre><h3 id="Trace-Communication"><a class="docs-heading-anchor" href="#Trace-Communication">Trace Communication</a><a id="Trace-Communication-1"></a><a class="docs-heading-anchor-permalink" href="#Trace-Communication" title="Permalink"></a></h3><pre><code class="language-julia hljs">for r in plan.rank_ids
    println(&quot;Rank $rank sends to $r: $(length(plan.send_bufs[i])) values&quot;)
end</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../api/">« API Reference</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Wednesday 10 December 2025 14:22">Wednesday 10 December 2025</span>. Using Julia version 1.10.10.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
